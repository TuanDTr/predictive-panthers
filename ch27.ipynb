{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5222c239-40bd-471a-b5db-d5c668471744",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install monai[nibabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d882bcb0-3352-497f-9db2-6679e4e8f67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    Invertd,\n",
    "    SpatialPadd\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.nets import UNet\n",
    "from monai.networks.layers import Norm\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
    "from monai.config import print_config\n",
    "from monai.apps import download_and_extract\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import tempfile\n",
    "import shutil\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2f5f04a-17b2-42e2-b464-29ddf6c9aaef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/tmp/tmp6sljes8c\n"
     ]
    }
   ],
   "source": [
    "root_dir = tempfile.mkdtemp()\n",
    "print(root_dir)\n",
    "data_root_dir = os.path.join(root_dir, \"data\")\n",
    "os.makedirs(data_root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f81eace-0728-4989-9772-3faa38278618",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/dataset.json...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_10.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_12.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_13.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_14.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_16.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_17.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_18.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_19.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_2.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_20.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_21.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_22.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_25.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_26.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_28.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_24.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_27.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_29.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_3.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_32.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_33.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_31.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_38.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_41.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_40.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_44.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_47.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_8.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_46.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_49.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_53.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_45.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_6.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_56.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_52.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_59.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_61.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_60.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_63.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_62.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTr/spleen_9.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_1.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_11.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_15.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_23.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_30.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_34.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_35.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_36.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_37.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_39.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_42.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_43.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_48.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_50.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_51.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_54.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_55.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_57.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_58.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/imagesTs/spleen_7.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_10.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_12.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_13.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_14.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_16.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_17.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_18.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_19.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_2.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_20.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_21.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_22.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_24.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_25.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_26.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_27.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_28.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_29.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_3.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_32.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_31.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_33.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_38.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_41.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_40.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_44.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_45.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_46.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_47.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_49.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_52.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_53.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_56.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_59.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_6.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_60.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_61.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_62.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_63.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_9.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/metadata/hierarchy.json...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/artifactFiles/labelsTr/spleen_8.nii.gz...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/readmeFiles/A large annotated medical image dataset for the development and evaluation of segmentation algorithms.pdf...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/readmeFiles/License CC BY-SA 4.0.txt...\n",
      "Copying gs://marketplace-2xim6sjc/Medical Decathlon Spleen/148/readmeFiles/The Medical Segmentation Decathlon.pdf...\n",
      "| [107/107 files][  1.5 GiB/  1.5 GiB] 100% Done                                \n",
      "Operation completed over 107 objects/1.5 GiB.                                    \n"
     ]
    }
   ],
   "source": [
    "# Download data\n",
    "!gsutil -m cp -r \"gs://marketplace-2xim6sjc/Medical Decathlon Spleen\" {data_root_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1db925a7-68ed-4e9f-b09f-788dc4c4ac7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(data_root_dir, \"Medical Decathlon Spleen/148/artifactFiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "476e4ebc-c21e-4c6d-817c-df101c8090fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_images = sorted(glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
    "train_labels = sorted(glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
    "data_dicts = [{\"image\": image_name, \"label\": label_name} for image_name, label_name in zip(train_images, train_labels)]\n",
    "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8e9d296-0b29-48cf-a87f-5c6de8e7243e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_determinism(seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75c81520-3ea4-47ec-9163-96285e749fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "        SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(96, 96, 96)),\n",
    "        RandCropByPosNegLabeld(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            label_key=\"label\",\n",
    "            spatial_size=(96, 96, 96),\n",
    "            pos=1,\n",
    "            neg=1,\n",
    "            num_samples=4,\n",
    "            image_key=\"image\",\n",
    "            image_threshold=0,\n",
    "        ),\n",
    "        # user can also add other random transforms\n",
    "        # RandAffined(\n",
    "        #     keys=['image', 'label'],\n",
    "        #     mode=('bilinear', 'nearest'),\n",
    "        #     prob=1.0, spatial_size=(96, 96, 96),\n",
    "        #     rotate_range=(0, 0, np.pi/15),\n",
    "        #     scale_range=(0.1, 0.1, 0.1)),\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"],\n",
    "            a_min=-57,\n",
    "            a_max=164,\n",
    "            b_min=0.0,\n",
    "            b_max=1.0,\n",
    "            clip=True,\n",
    "        ),\n",
    "        # SpatialPadd(keys=[\"image\", \"label\"], spatial_size=(96, 96, 96)),\n",
    "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
    "        Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccd80b03-ec10-480c-9a88-6b3043571a77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading dataset: 100%|██████████| 32/32 [00:34<00:00,  1.08s/it]\n",
      "Loading dataset: 100%|██████████| 9/9 [00:06<00:00,  1.47it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=1.0, num_workers=4)\n",
    "# train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "\n",
    "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
    "# to generate 2 x 4 images for network training\n",
    "train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=4)\n",
    "\n",
    "val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
    "# val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f4a1d4-6537-4a3a-80e4-f29f18ff9d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
    "device = torch.device(\"cuda:0\")\n",
    "model = UNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    "    norm=Norm.BATCH,\n",
    ").to(device)\n",
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b056824-cade-4993-840b-753ffac9e27e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "epoch 1/2\n",
      "1/16, train_loss: 0.6680\n",
      "2/16, train_loss: 0.6792\n",
      "3/16, train_loss: 0.6834\n",
      "4/16, train_loss: 0.6849\n",
      "5/16, train_loss: 0.6857\n",
      "6/16, train_loss: 0.6920\n",
      "7/16, train_loss: 0.6590\n",
      "8/16, train_loss: 0.6759\n",
      "9/16, train_loss: 0.6681\n",
      "10/16, train_loss: 0.6563\n",
      "11/16, train_loss: 0.6539\n",
      "12/16, train_loss: 0.6792\n",
      "13/16, train_loss: 0.6526\n",
      "14/16, train_loss: 0.6629\n",
      "15/16, train_loss: 0.6517\n",
      "16/16, train_loss: 0.6292\n",
      "epoch 1 average loss: 0.6676\n",
      "----------\n",
      "epoch 2/2\n",
      "1/16, train_loss: 0.6618\n",
      "2/16, train_loss: 0.6614\n",
      "3/16, train_loss: 0.6438\n",
      "4/16, train_loss: 0.6484\n",
      "5/16, train_loss: 0.6577\n",
      "6/16, train_loss: 0.6419\n",
      "7/16, train_loss: 0.6516\n",
      "8/16, train_loss: 0.6140\n",
      "9/16, train_loss: 0.6245\n",
      "10/16, train_loss: 0.6492\n",
      "11/16, train_loss: 0.6294\n",
      "12/16, train_loss: 0.6113\n",
      "13/16, train_loss: 0.6226\n",
      "14/16, train_loss: 0.6431\n",
      "15/16, train_loss: 0.6437\n",
      "16/16, train_loss: 0.6450\n",
      "epoch 2 average loss: 0.6406\n",
      "saved new best metric model\n",
      "current epoch: 2 current mean dice: 0.0320\n",
      "best mean dice: 0.0320 at epoch: 2\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 2\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([AsDiscrete(to_onehot=2)])\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = (\n",
    "            batch_data[\"image\"].to(device),\n",
    "            batch_data[\"label\"].to(device),\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for val_data in val_loader:\n",
    "                val_inputs, val_labels = (\n",
    "                    val_data[\"image\"].to(device),\n",
    "                    val_data[\"label\"].to(device),\n",
    "                )\n",
    "                roi_size = (160, 160, 160)\n",
    "                sw_batch_size = 4\n",
    "                val_outputs = sliding_window_inference(val_inputs, roi_size, sw_batch_size, model)\n",
    "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                # compute metric for current iteration\n",
    "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "\n",
    "            # aggregate the final mean dice result\n",
    "            metric = dice_metric.aggregate().item()\n",
    "            # reset the status for next validation round\n",
    "            dice_metric.reset()\n",
    "\n",
    "            metric_values.append(metric)\n",
    "            if metric > best_metric:\n",
    "                best_metric = metric\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "            print(\n",
    "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
    "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
    "                f\"at epoch: {best_metric_epoch}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2311d3c-ecc7-4dbc-87b7-6afce08ffeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_65513/762177899.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/var/tmp/tmp6sljes8c/best_metric_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_metric_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1319\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1317\u001b[0m     pickle_load_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1319\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1321\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1322\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1323\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:659\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 659\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:640\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/var/tmp/tmp6sljes8c/best_metric_model.pth'"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"best_metric_model.pth\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6f1b7-5b77-4d54-8bde-f07721fe0ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
